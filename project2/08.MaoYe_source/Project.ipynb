{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "working_directory = 'C:/Users/MAngO/Dropbox/UST/Year I/Yuany CSIC/Project'\n",
    "os.chdir(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\MAngO\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.937 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "with open('dream_figures.txt', 'rb') as f:\n",
    "    characters_names = [line.decode('utf-8').strip('\\n') for line in f.readlines()]\n",
    "for name in characters_names:\n",
    "    jieba.add_word(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAngO\\Anaconda3\\envs\\tf\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Training of word2vec\n",
    "import gensim\n",
    "with open('dream.txt', 'rb') as f:\n",
    "    data = [line.decode('utf-8').strip() for line in f.readlines()if line.decode('utf-8').strip()]\n",
    "\n",
    "sentences = []\n",
    "for line in data:\n",
    "    words = list(jieba.cut(line))\n",
    "    sentences.append(words)\n",
    "    \n",
    "# By default setting, we train word2vec with CBOW and Negative-Sampling, words with count less than 10 are removed\n",
    "model = gensim.models.Word2Vec(sentences,size=100,window=5,min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08804332, -0.53033477, -0.66613024, -0.1551435 , -0.35534421,\n",
       "       -0.03870843, -0.21183251,  0.58766025, -0.25875148, -0.84310699,\n",
       "       -0.73783082, -0.55144173,  0.05687124, -1.66058624,  1.37546086,\n",
       "       -0.57371366, -0.14626463, -0.34558025, -0.38663989, -0.1301972 ,\n",
       "        0.17591901, -0.50929439,  0.08011577,  0.42731753, -0.23153152,\n",
       "        0.38623524,  0.15924992,  0.71490836,  0.20342124, -0.23314959,\n",
       "        1.15066624, -0.87204641,  0.66758949,  0.78183824, -0.78160524,\n",
       "        0.07213362,  0.05746133,  0.33127135,  0.16983888, -0.01203949,\n",
       "        0.42158478, -0.66407669,  0.33799288, -0.38730383,  0.63126647,\n",
       "        0.380124  ,  0.11783867,  0.28056723,  1.1385392 ,  0.67765635,\n",
       "        0.38157699,  0.81880951, -0.66098022,  0.30383947, -0.98767942,\n",
       "        0.25376529,  0.60259086, -0.02757449,  0.6801005 ,  0.18785532,\n",
       "        0.50834233,  0.1595711 ,  0.97904354, -0.05315511,  0.01344215,\n",
       "       -0.44681928, -0.30663002, -0.42049739, -0.19419238, -0.60563499,\n",
       "        0.91494852,  0.72853374, -0.59597886, -0.42614529, -0.31041452,\n",
       "       -0.91477531,  0.51080418,  0.42588976, -0.39858478,  0.1015    ,\n",
       "       -0.00990862, -0.37983808,  0.32104003, -0.14995255,  0.94735473,\n",
       "        0.55601454, -0.06220052,  0.36464047,  0.10559884, -0.9368782 ,\n",
       "        1.61520743,  0.38089246,  0.51106268, -0.7318849 ,  0.20480959,\n",
       "        1.08949578,  0.77025884,  0.67629451, -1.31966186, -0.6485731 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['宝玉']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('贾琏', 0.9161045551300049),\n",
       " ('贾母', 0.8976159691810608),\n",
       " ('尤氏', 0.8508528470993042),\n",
       " ('凤姐儿', 0.8405201435089111),\n",
       " ('麝月', 0.8253404498100281),\n",
       " ('平儿', 0.825271725654602),\n",
       " ('贾芸', 0.8228203058242798),\n",
       " ('袭人', 0.8221731185913086),\n",
       " ('鸳鸯', 0.8218496441841125),\n",
       " ('刘姥姥', 0.8152858018875122)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use gensim built-in function to test the most relevant figures with given relationship: (sum(positive) - negative)\n",
    "model.most_similar(positive=['王夫人', '凤姐'], negative=[ '薛姨妈'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('袭人', 0.8978891372680664),\n",
       " ('凤姐', 0.855692982673645),\n",
       " ('林黛玉', 0.8433758020401001),\n",
       " ('紫鹃', 0.8423019647598267),\n",
       " ('晴雯', 0.8416805863380432),\n",
       " ('贾琏', 0.8381054997444153),\n",
       " ('薛姨妈', 0.8275371789932251),\n",
       " ('香菱', 0.8089209794998169),\n",
       " ('探春', 0.806232213973999),\n",
       " ('王夫人', 0.7977675199508667)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['宝玉', '宝钗'], negative=[ '黛玉'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load character names and corresponding word vectors to do clustering in next step\n",
    "import numpy as np\n",
    "all_names = []\n",
    "\n",
    "word_vectors = None\n",
    "np_names = None\n",
    "for name in characters_names:\n",
    "    if name in model:\n",
    "        all_names.append(name)\n",
    "for name in all_names:\n",
    "    if word_vectors is None:\n",
    "        word_vectors = model[name]\n",
    "    else:\n",
    "        word_vectors = np.vstack((word_vectors, model[name]))\n",
    "        np_names = np.array(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use KMeans to cluster character names with their word vectors\n",
    "import scipy\n",
    "from sklearn.cluster import KMeans\n",
    "def kmeans(np_names, word_vectors, N):\n",
    "    label = KMeans(N).fit(word_vectors).labels_\n",
    "    n = scipy.stats.mode(label).mode\n",
    "\n",
    "    remain_names = np_names[label != n]\n",
    "    remain_vectors = word_vectors[label != n]\n",
    "    remain_label = KMeans(N).fit(remain_vectors).labels_\n",
    "\n",
    "    for i in range(N):\n",
    "        print(\"类别{}：\".format(i + 1))\n",
    "        for idx, name in enumerate(remain_names[remain_label == i]):\n",
    "            print(name, end=\", \")\n",
    "            if idx % 10 == 9:\n",
    "                print('')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别1：\n",
      "贾赦, 贾政, 贾珍, 贾母, 邢夫人, 尤氏, \n",
      "类别2：\n",
      "黛玉, 宝钗, 贾琏, 宝玉, 王夫人, 凤姐, 薛姨妈, 李纨, 袭人, 紫鹃, \n",
      "鸳鸯, 平儿, \n",
      "类别3：\n",
      "贾环, 贾蓉, 贾芸, 林黛玉, 香菱, 刘姥姥, 晴雯, 麝月, 秋纹, 雪雁, \n",
      "琥珀, 莺儿, 芳官, 周瑞家的, \n"
     ]
    }
   ],
   "source": [
    "kmeans(np_names, word_vectors, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别1：\n",
      "贾芸, 林黛玉, 香菱, 刘姥姥, 晴雯, 麝月, 紫鹃, 鸳鸯, 平儿, 周瑞家的, \n",
      "\n",
      "类别2：\n",
      "贾环, 贾瑞, 贾蓉, 贾兰, 贾蔷, 史湘云, 薛蟠, 薛蝌, 妙玉, 赵姨娘, \n",
      "秋纹, 司棋, 雪雁, 琥珀, 莺儿, 丰儿, 彩云, 翠缕, 宝蟾, 茗烟, \n",
      "焙茗, 李贵, 兴儿, 芳官, 秦钟, 冯紫英, 赖大, 林之孝, 林之孝家的, 尤二姐, \n",
      "\n",
      "类别3：\n",
      "贾琏, 贾母, 王夫人, 凤姐, 薛姨妈, 李纨, \n",
      "类别4：\n",
      "贾赦, 贾政, 贾珍, 邢夫人, 尤氏, \n",
      "类别5：\n",
      "黛玉, 宝钗, 宝玉, 袭人, \n"
     ]
    }
   ],
   "source": [
    "kmeans(np_names, word_vectors, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
